{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "from torch import nn\n",
    "import sys, os\n",
    "\n",
    "# Add the 'modules/deepspeech/src/' directory to the system path\n",
    "sys.path.insert(0, os.path.abspath('../modules/deepspeech/src'))\n",
    "import deepspeech\n",
    "\n",
    "# from deepspeech.networks.utils import OverLastDim\n",
    "from deepspeech.data import preprocess\n",
    "from torchvision.transforms import Compose\n",
    "from deepspeech.data.loader import collate_input_sequences\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from deepspeech.data.datasets.librispeech import LibriSpeech\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(levelname)s: %(message)s')\n",
    "# ignore from matplotlib \n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "\n",
    "from models.ds1 import DeepSpeech1WithContextFrames\n",
    "from ctc.ctc_loss_imp import ctc_loss_imp\n",
    "from data.librisubset import LibriSampledDataset\n",
    "from utils.plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Reconstructing data point at index: 0\n",
      "INFO: Optimizer: Adam\n",
      "INFO: Learning rate: 0.5\n",
      "INFO: Regularization: None\n",
      "INFO: Regularization weight: 0\n",
      "INFO: Number of iterations: 10000\n",
      "INFO: logging experiment to /scratch/f006pq6/projects/asr-grad-reconstruction/logging/example_v2/idx_0_init_same_opt_Adam_lr_0.5_reg_None_regw_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Device: cuda:0\n",
      "INFO: Network: DeepSpeech1WithContextFrames\n",
      "/tmp/ipykernel_1017433/995365913.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(os.path.join(FLAGS.exp_path, 'net_params.pt')))\n",
      "INFO: net_params.pt loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'test-clean' already downloaded and verified.\n",
      "number of utterances: 200\n",
      "example shape of input: torch.Size([101, 26])\n",
      "number of frames in example: 101\n",
      "example target: a baron has a cover of assay\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_device_net(FLAGS):\n",
    "    device = 'cuda:0'\n",
    "    net = DeepSpeech1WithContextFrames(FLAGS.n_context, FLAGS.drop_prob).to(device)\n",
    "    return device, net\n",
    "    \n",
    "\n",
    "def get_dataset_loader(net):\n",
    "    dataset_1 = LibriSpeech(root='/scratch/f006pq6/datasets/librispeech/', subsets=['test-clean'], download=True,\n",
    "                          transform=net.transform)\n",
    "            \n",
    "    file_path = '../samples/samples_below_4s_bucket_500_all_minh.txt'\n",
    "    dataset = LibriSampledDataset(file_path, min_length=2000, max_length=3000, transform=net.transform)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset,\n",
    "                                         collate_fn=collate_input_sequences,\n",
    "                                         pin_memory=torch.cuda.is_available(),\n",
    "                                         num_workers=4,\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=False)\n",
    "    print('number of utterances:', len(dataset))\n",
    "    print('example shape of input:', dataset[0][0][0].shape)\n",
    "    print('number of frames in example:', dataset[0][0][1])\n",
    "    print('example target:', dataset[0][1])\n",
    "    return dataset, loader\n",
    "\n",
    "def get_datapoint_i(loader_iterator, idx):\n",
    "    for i in range(idx):\n",
    "        next(loader_iterator)\n",
    "    next_item = next(loader_iterator)\n",
    "    print('next item shape of input:', next_item[0][0].shape)\n",
    "    print('next item number of frames:', next_item[0][1])\n",
    "    print('next item target:', next_item[1])\n",
    "    return next_item\n",
    "\n",
    "\n",
    "\n",
    "def grad_distance(g1, g2):\n",
    "    # use 1-costine similarity\n",
    "    return 1 - torch.nn.functional.cosine_similarity(g1.reshape(1,-1), g2.reshape(1,-1))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Meta loss\n",
    "# ------------------------------------------------------------------------------\n",
    "def meta_loss(output, targets, output_sizes, target_sizes, dldw_targets,  params_to_match, loss_func):\n",
    "    loss = loss_func(output, targets)\n",
    "    dldws = torch.autograd.grad(loss, params_to_match, create_graph=True)\n",
    "    # loss = ((dldw-dldw_target)**2).mean() #MSE\n",
    "    #loss = 1 - torch.nn.functional.cosine_similarity(dldw.reshape(1,-1), dldw_target.reshape(1,-1))    \n",
    "    loss = 0 \n",
    "    for dldw, dldw_target in zip(dldws, dldw_targets):\n",
    "        #loss += torch.nn.functional.mse_loss(dldw, dldw_target)\n",
    "        loss += grad_distance(dldw, dldw_target)\n",
    "\n",
    "    return loss,dldws\n",
    "\n",
    "\n",
    "def init_a_point(inputs, FLAGS):\n",
    "    if FLAGS.init_method == 'uniform':\n",
    "        # init x_init varialbe with unifrom [-1,1]\n",
    "        logging.info('init with uniform')\n",
    "        x_init = torch.rand_like(inputs) * 2 - 1\n",
    "    elif FLAGS.init_method == 'normal':\n",
    "        # init x_init varialbe with normal distribution\n",
    "        logging.info('init with normal')\n",
    "        x_init = torch.randn_like(inputs)\n",
    "    elif FLAGS.init_method == 'same':\n",
    "        # init x_init varialbe with same as inputs\n",
    "        logging.info('init with same') \n",
    "        x_init = inputs.clone()\n",
    "    elif FLAGS.init_method == 'same_noisy':\n",
    "        # init x_init varialbe with same as inputs + noise\n",
    "        logging.info('init with same_noisy')\n",
    "        x_init = inputs.clone() + torch.randn_like(inputs) * 0.01\n",
    "\n",
    "    logging.info('init mean, std:{} {}'.format(x_init.mean(), x_init.std()))\n",
    "    x_param = torch.nn.Parameter(x_init.to(device),requires_grad=True)\n",
    "    # x_param_full = torch.concat([x_param, x_pad], dim=2)\n",
    "    return x_param\n",
    "\n",
    "def tv_norm( x):\n",
    "    # Compute differences along the y-axis\n",
    "    dy = torch.abs(x[:, :, 1:, :] - x[:, :, :-1, :])\n",
    "    # Compute differences along the x-axis\n",
    "    dx = torch.abs(x[:, :, :, 1:] - x[:, :, :, :-1])\n",
    "    # Compute total variation\n",
    "    tv = torch.sum(dx) + torch.sum(dy)\n",
    "    # Scale by the strength parameter\n",
    "    return tv\n",
    "\n",
    "\n",
    "# create a optimization loop function\n",
    "def optimization_loop(inputs, x_param, output_sizes, target_sizes,\n",
    "                       optimizer, scheduler, net, \n",
    "                       dldw_targets , params_to_match, targets,  FLAGS):\n",
    "\n",
    "    loss_func = lambda x,y :ctc_loss_imp(x, y, output_sizes, target_sizes,reduction='mean')\n",
    "\n",
    "    i=0\n",
    "    loss_history = []\n",
    "    loss_gm_history = []\n",
    "    loss_reg_history = []\n",
    "    stop_condition = False\n",
    "    while i < FLAGS.max_iter or not stop_condition:\n",
    "        # x_param_full= torch.concat([x_param, x_pad], dim=2)\n",
    "        out = net(x_param) # 1 176 29\n",
    "        out = out.log_softmax(-1)\n",
    "        # mloss, dldw_f = meta_loss(output, targets, output_sizes, target_sizes, dldw_target,  weight_param)\n",
    "        mloss, dldws = meta_loss(out, targets, None, None, dldw_targets,  params_to_match, loss_func)\n",
    "        gm_weight_distance = grad_distance(dldws[0], dldw_targets[0])\n",
    "        gm_bias_distance   = grad_distance(dldws[1], dldw_targets[1])\n",
    "\n",
    "        # regloss = tv_norm(x_param)\n",
    "        if FLAGS.reg == 'L2':\n",
    "            regloss = torch.norm(x_param, p=2)\n",
    "        elif FLAGS.reg == 'L1':\n",
    "            pass\n",
    "        elif FLAGS.reg == 'TV':\n",
    "            # need to make x_param from [n_frame, batch size, n_features] to [batch size, 1, n_features, n_frame]\n",
    "            regloss = tv_norm(x_param.permute(1,0,2).unsqueeze(1))\n",
    "        else:\n",
    "            regloss = torch.tensor(0.0)\n",
    "       \n",
    "        loss = (1-FLAGS.reg_weight)* mloss + FLAGS.reg_weight * regloss\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        grad = x_param.grad.data\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(x_param, 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        ## PROJECT NON NEGATIVE\n",
    "        # x_param = x_param.clamp(min=0)\n",
    "        # with torch.no_grad():\n",
    "        #x_param.data = torch.clamp( x_param.data, min=0)\n",
    "\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "        loss_gm_history.append(mloss.item() )\n",
    "        loss_reg_history.append(regloss.item() )\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            logging.info('Iter, Loss (A-G-Gw-Gb-R), Gradient Norm, Learning Rate: {:4d}, {:.8f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'\\\n",
    "                        .format(i, loss.item(), mloss.item(),  gm_weight_distance.item(), gm_bias_distance.item(), regloss.item()\n",
    "            , grad.norm().item(), optimizer.param_groups[0][\"lr\"]))\n",
    "            # scheduler.step(mloss.item())\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            plot_four_graphs(inputs.detach(), x_param.detach(), loss_history, loss_gm_history,loss_reg_history ,i)\n",
    "            pass\n",
    "            \n",
    "        \n",
    "        i+=1\n",
    "        # stet stop condition true if loss not decrease in last 100 iteration\n",
    "        if i>100 and loss_history[-1] > min(loss_history[-100:]):\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            stop_condition\n",
    "    # save the reconstructed x_param, remember to detach and cpu it..\n",
    "    save_path = os.path.join(FLAGS.exp_path, 'x_param_last.pt')\n",
    "    torch.save(x_param.detach().cpu(), save_path)\n",
    "\n",
    "    return x_param\n",
    "\n",
    "# optimization_loop(x_param, optimizer, scheduler, net, dldw_target, weight_param, targets)\n",
    "\n",
    "# plot_mfcc(inputs.cpu().squeeze())\n",
    "\n",
    "# plot_mfcc(x_param.cpu().detach().squeeze())\n",
    "\n",
    "# plot_four_graphs(inputs.detach(), x_param.detach(), loss_history, loss_gm_history,loss_reg_history ,i)\n",
    "\n",
    "\n",
    "\n",
    "## write a main entry point for a python script file\n",
    "# that has args\n",
    "# 1. choose what is the index of the data point to reconstruct\n",
    "# 2. choose the learning rate\n",
    "# 3. choose what kind or regularization (L1, L2, TV)\n",
    "# 4. choose the weight of that regularization [0,1]\n",
    "# 5. choose the number of iterations\n",
    "# 6. choose number of seeds to try\n",
    "# python3 main.py --index 0 --lr 0.1 --reg L2 --reg_weight 0.05 --iterations 10000 --seeds 5\n",
    "# example of calling the main function with all args name\n",
    "# main(index=0, lr=0.1, reg='L2', reg_weight=0.05, iterations=1000, n_seeds=5)        \n",
    "\n",
    "\n",
    "def main(FLAGS):\n",
    "    \"\"\"\n",
    "    Main function for reconstructing data points with specified hyperparameters.\n",
    "   \n",
    "    Parameters:\n",
    "    - index: Index of the data point to reconstruct.\n",
    "    - lr: Learning rate for optimization.\n",
    "    - reg: Type of regularization ('L1', 'L2', 'TV').\n",
    "    - reg_weight: Weight of the regularization term.\n",
    "    - iterations: Number of iterations for the optimization.\n",
    "    \"\"\"\n",
    "    # Change all print statements to logging statements\n",
    "    logging.info('Reconstructing data point at index: {}'.format(FLAGS.index))\n",
    "    logging.info('Optimizer: {}'.format(FLAGS.optimizer_name))\n",
    "    logging.info('Learning rate: {}'.format(FLAGS.lr))\n",
    "    logging.info('Regularization: {}'.format(FLAGS.reg))\n",
    "    logging.info('Regularization weight: {}'.format(FLAGS.reg_weight))\n",
    "    logging.info('Number of iterations: {}'.format(FLAGS.iterations))\n",
    "\n",
    "    #check if exp_path exists or create\n",
    "    if not os.path.exists(FLAGS.exp_path):\n",
    "        os.makedirs(FLAGS.exp_path)\n",
    "        logging.info('exp_path {} created'.format(FLAGS.exp_path))\n",
    "    if not os.path.exists(os.path.join(FLAGS.exp_path, 'figures')):\n",
    "        os.makedirs(os.path.join(FLAGS.exp_path, 'figures'))    \n",
    "    logging.info('logging experiment to {}'.format(FLAGS.exp_path))\n",
    "\n",
    "    device, net = get_device_net(FLAGS)\n",
    "    logging.info('Device: {}'.format(device))\n",
    "    logging.info('Network: {}'.format((net.__class__.__name__)))\n",
    "\n",
    "\n",
    "    # check if example/net_params.pt exists, if not create by saving the net state_dict, if yes then load\n",
    "    if not os.path.exists(os.path.join(FLAGS.exp_path, 'net_params.pt')):\n",
    "        torch.save(net.state_dict(), os.path.join(FLAGS.exp_path, 'net_params.pt'))\n",
    "        logging.info('net_params.pt created')\n",
    "    else:\n",
    "        net.load_state_dict(torch.load(os.path.join(FLAGS.exp_path, 'net_params.pt')))\n",
    "        logging.info('net_params.pt loaded')\n",
    "\n",
    "     # get device net dataset loader datapoint i\n",
    "    if FLAGS.index != 0:\n",
    "        raise ValueError('script now run for index 0 only')\n",
    "\n",
    "    # check if input.pt exists, if not create by loading the next_item and save it\n",
    "    # if not os.path.exists(os.path.join(FLAGS.exp_path, 'input.pt')):\n",
    "    #     dataset, loader = get_dataset_loader(net)\n",
    "    #     next_item = get_datapoint_i(iter(loader), 0)\n",
    "    #     torch.save(next_item, os.path.join(FLAGS.exp_path, 'input.pt'))\n",
    "    #     logging.info('input.pt created')\n",
    "    # else:\n",
    "    #     next_item = torch.load(os.path.join(FLAGS.exp_path, 'input.pt'))\n",
    "    #     logging.info('input.pt loaded')\n",
    "    dataset, loader = get_dataset_loader(net)\n",
    "    next_item = get_datapoint_i(iter(loader), 0)\n",
    "\n",
    "    logging.info('')\n",
    "\n",
    "    target_transform = Compose([str.lower,\n",
    "                        net.ALPHABET.get_indices,\n",
    "                        torch.IntTensor])\n",
    "\n",
    "\n",
    "    inputs = next_item[0][0]\n",
    "    logging.info('inputs mean and std: {}, {}'.format(inputs.mean(), inputs.std()))\n",
    "    input_sizes = torch.Tensor([inputs.shape[0]]).int()\n",
    "    targets = target_transform(next_item[1][0])\n",
    "    target_sizes = torch.Tensor([len(targets)]).int()\n",
    "\n",
    "    # transfer the data to the GPU\n",
    "    inputs = inputs.to(device)\n",
    "    input_sizes = input_sizes.to(device)\n",
    "    targets = targets.to(device)\n",
    "    target_sizes = target_sizes.to(device)\n",
    "\n",
    "    # get the target gradient\n",
    "    # param to match, a list of pointer to params\n",
    "    params_to_match = [net.network.out.module[0].weight, net.network.out.module[0].bias]\n",
    "    out = net(inputs)\n",
    "    output_sizes = torch.Tensor([out.size(0)]).int().to(device)\n",
    "    out =  out.log_softmax(-1)\n",
    "    loss_func = lambda x,y :ctc_loss_imp(x, y, output_sizes, target_sizes,reduction='mean')\n",
    "    loss_func_lib   = torch.nn.CTCLoss()\n",
    "    loss = loss_func(out, targets)\n",
    "    loss_lib = loss_func_lib(out.cpu(), targets.cpu(), output_sizes.cpu(), target_sizes.cpu())\n",
    "    logging.debug('loss: {}'.format(loss.item()))\n",
    "    logging.debug('loss by pt lib: {}'.format(loss_lib.item()))\n",
    "    dldw_targets = torch.autograd.grad(loss, params_to_match)\n",
    "\n",
    "    ## zero out small values keep 10% largest dldw_target\n",
    "    # logging.info('zero out small values keep 10% largest dldw_target')\n",
    "    # dldw_target = dldw_target * (dldw_target.abs() > dldw_target.abs().topk(int(0.1*dldw_target.numel()))[0][-1])\n",
    "    for ip, p in enumerate(params_to_match):\n",
    "        p.requires_grad = True\n",
    "        logging.debug('matching {}. params with shape {} and norm {} first ten {}'.format(ip, p.shape, p.norm(), p.flatten()[:10]))\n",
    "        logging.debug('                    gradient norm {}'.format(dldw_targets[ip].norm()))\n",
    "\n",
    "    # init x_param\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    x_init = init_a_point(inputs, FLAGS)\n",
    "    # x_init = torch.randn_like(inputs).to(device)\n",
    "    x_param = torch.nn.Parameter(x_init.to(device), requires_grad=True)\n",
    "    logging.debug('init mean, std: {}, {}'.format(x_init.mean(), x_init.std()))\n",
    "\n",
    "    if FLAGS.optimizer_name.lower() == 'adam':\n",
    "        optimizer = optim.Adam([x_param], lr=FLAGS.lr)\n",
    "    elif FLAGS.optimizer_name.lower() == 'sgd':\n",
    "        optimizer = optim.SGD([x_param], lr=FLAGS.lr)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {FLAGS.optimizer_name}\")\n",
    "\n",
    "    # reduce lr at epoch 250, 500, 750 half\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=list(range(250,2000,250)), gamma=0.5)\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=.5,patience=50)\n",
    "\n",
    "\n",
    "    # suggest an experiment name base on datapoint index, optimizer name,  learning rate, regularizer, regularizer weight\n",
    "    logging.info('Experiment Name: {}'.format(os.path.basename(FLAGS.exp_path)))\n",
    "\n",
    "    optimization_loop(inputs, x_param, output_sizes, target_sizes,\n",
    "                       optimizer, scheduler, net,\n",
    "                       dldw_targets = dldw_targets, params_to_match =  params_to_match, targets = targets,  FLAGS= FLAGS)\n",
    "\n",
    "\n",
    "## main\n",
    "\n",
    "\n",
    "FLAGS = argparse.Namespace(index=0, optimizer_name='Adam', lr=0.5, reg='None', reg_weight=0, iterations=10000, n_seeds=5, max_iter=10000,\n",
    "                            n_context=6, drop_prob=0, init_method='same')\n",
    "\n",
    "exp_path='/scratch/f006pq6/projects/asr-grad-reconstruction/logging/example_v2/'\n",
    "exp_name = f\"idx_{FLAGS.index}_init_{FLAGS.init_method}_opt_{FLAGS.optimizer_name}_lr_{FLAGS.lr}_reg_{FLAGS.reg}_regw_{FLAGS.reg_weight}\"\n",
    "FLAGS.exp_path=os.path.join(exp_path, exp_name)\n",
    "\n",
    "main(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr-grad-reconstruction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
