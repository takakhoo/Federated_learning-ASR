{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libra imp:                     tensor(23.4569, grad_fn=<MeanBackward0>)\n",
      "base imp:                      tensor(23.4569, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "batched_ctc:                   tensor(23.4569, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "batched_ctc_v2:                tensor(23.4569, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "batched_ctc_logspace:          tensor(23.4569, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "batched_ctc_logspace_scale:    tensor(23.4569, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "def ctc_loss_imp(log_probs, targets, input_lengths, target_lengths, blank=0, reduction='mean'):\n",
    "    input_lengths = torch.as_tensor(input_lengths, dtype=torch.long)\n",
    "    target_lengths = torch.as_tensor(target_lengths, dtype=torch.long)\n",
    "    dt = log_probs.dtype\n",
    "    log_probs = log_probs.double()  # we need the accuracy as we are not in logspace\n",
    "    targets = targets.long()\n",
    "    cum_target_lengths = target_lengths.cumsum(0)\n",
    "    losses = []\n",
    "    for i in range(log_probs.size(1)):\n",
    "        input_length = input_lengths[i].item()\n",
    "        target_length = target_lengths[i].item()\n",
    "        cum_target_length = cum_target_lengths[i].item()\n",
    "        # ==========================================================================================================\n",
    "        targets_prime = targets.new_full((2 * target_length + 1,), blank)\n",
    "        if targets.dim() == 2:\n",
    "            targets_prime[1::2] = targets[i, :target_length]\n",
    "        else:\n",
    "            targets_prime[1::2] = targets[cum_target_length - target_length:cum_target_length]\n",
    "        # ==========================================================================================================\n",
    "        probs = log_probs[:input_length, i].exp()\n",
    "        # ==========================================================================================================\n",
    "        alpha = log_probs.new_zeros((target_length * 2 + 1,))\n",
    "        alpha[0] = probs[0, blank]\n",
    "        alpha[1] = probs[0, targets_prime[1]]\n",
    "        mask_third = (targets_prime[:-2] != targets_prime[2:])\n",
    "        for t in range(1, input_length):\n",
    "            alpha_next = alpha.clone()\n",
    "            alpha_next[1:] += alpha[:-1]\n",
    "            alpha_next[2:] += torch.where(mask_third, alpha[:-2], alpha.new_zeros(1))\n",
    "            alpha = probs[t, targets_prime] * alpha_next\n",
    "        # ==========================================================================================================\n",
    "        losses.append(-alpha[-2:].sum().log()[None])\n",
    "    output = torch.cat(losses, 0)\n",
    "    if reduction == 'mean':\n",
    "        return (output / target_lengths.to(dtype=output.dtype, device=output.device)).mean()\n",
    "    elif reduction == 'sum':\n",
    "        return output.sum()\n",
    "    output = output.to(dt)\n",
    "    return output\n",
    "\n",
    "def batched_ctc(log_probs: Tensor, targets: Tensor, input_lengths: Tensor, target_lengths: Tensor, blank=0):\n",
    "    # out = torch.nn.functional.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "    batch_size = targets.size(0)\n",
    "    max_target_length = targets.size(1)\n",
    "    max_input_length  = log_probs.size(0)\n",
    "    targets_prime = targets.new_full((batch_size, 2 * max_target_length + 1,), blank)\n",
    "    targets_prime[:, 1::2] = targets[:, :max_target_length]\n",
    "    log_probs = log_probs.double()\n",
    "    probs = log_probs.exp()\n",
    "    # Initialization\n",
    "    alpha = log_probs.new_zeros((batch_size, max_target_length * 2 + 1, ))\n",
    "    alpha[:, 0] = probs[0, :, blank]\n",
    "    alpha[:, 1] = probs[0].gather(1, targets_prime[:, 1].unsqueeze(-1)).squeeze(-1)\n",
    "    mask_third = targets_prime[:, :-2] != targets_prime[:, 2:]\n",
    "    mask_third = targets_prime[:, :-2] != targets_prime[:, 2:]\n",
    "    zero_tensor = torch.zeros_like(alpha[:, :-2])\n",
    "    for t in range(1, max_input_length):\n",
    "        alpha_next = alpha.clone()\n",
    "        alpha_next[:, 1:] += alpha[:, :-1]\n",
    "        alpha_next[:, 2:] += torch.where(mask_third, alpha[:, :-2], zero_tensor)\n",
    "        alpha = probs[t].gather(1, targets_prime) * alpha_next\n",
    "\n",
    "    tg = target_lengths.unsqueeze(1)\n",
    "\n",
    "    out = -(alpha.gather(1, tg*2-1) + alpha.gather(1, tg*2)).log().squeeze()\n",
    "    # out = -alpha[:, -2:].sum(-1).log()\n",
    "    out = (out / target_lengths).mean()\n",
    "    #ctx.save_for_backward(log_probs, targets, input_lengths, target_lengths, alpha)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def batched_ctc_v2(log_probs: Tensor, targets: Tensor, input_lengths: Tensor, target_lengths: Tensor, blank=0):\n",
    "    '''\n",
    "    same as batched_ctc but use different way to calculate alpha next \n",
    "    \n",
    "    '''\n",
    "    # out = torch.nn.functional.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "    batch_size = targets.size(0)\n",
    "    max_target_length = targets.size(1)\n",
    "    max_input_length  = log_probs.size(0)\n",
    "    targets_prime = targets.new_full((batch_size, 2 * max_target_length + 1,), blank)\n",
    "    targets_prime[:, 1::2] = targets[:, :max_target_length]\n",
    "    log_probs = log_probs.double()\n",
    "    probs = log_probs.exp()\n",
    "    # Initialization\n",
    "    alpha = log_probs.new_zeros((batch_size, max_target_length * 2 + 1, ))\n",
    "    alpha[:, 0] = probs[0, :, blank]\n",
    "    alpha[:, 1] = probs[0].gather(1, targets_prime[:, 1].unsqueeze(-1)).squeeze(-1)\n",
    "    mask_third = targets_prime[:, :-2] != targets_prime[:, 2:]\n",
    "    zero_tensor = torch.zeros_like(alpha[:, :-2])\n",
    "    for t in range(1, max_input_length):\n",
    "        # init alpha_next to be zero like alpha\n",
    "        alpha_next = alpha.clone()\n",
    "        alpha_next[:, 2:] += torch.where(mask_third, alpha[:, :-2],  zero_tensor) + alpha[:, 1:-1] \n",
    "        alpha_next[:, 1]  += alpha[:, 0] \n",
    "        # alpha_next[:, 0]  = alpha[:, 0]\n",
    "        \n",
    "        alpha = probs[t].gather(1, targets_prime) * alpha_next\n",
    "\n",
    "    tg = target_lengths.unsqueeze(1)\n",
    "\n",
    "    out = -(alpha.gather(1, tg*2-1) + alpha.gather(1, tg*2)).log().squeeze()\n",
    "    # out = -alpha[:, -2:].sum(-1).log()\n",
    "    out = (out / target_lengths).mean()\n",
    "    #ctx.save_for_backward(log_probs, targets, input_lengths, target_lengths, alpha)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def batched_ctc_logspace(log_probs: Tensor, targets: Tensor, input_lengths: Tensor, target_lengths: Tensor, blank=0):\n",
    "    # out = torch.nn.functional.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "    batch_size = targets.size(0)\n",
    "    max_target_length = targets.size(1)\n",
    "    max_input_length  = log_probs.size(0)\n",
    "    targets_prime = targets.new_full((batch_size, 2 * max_target_length + 1,), blank)\n",
    "    targets_prime[:, 1::2] = targets[:, :max_target_length]\n",
    "\n",
    "    # Initialization\n",
    "    alpha = torch.full(  (batch_size, max_target_length * 2 + 1, )     , float('-inf'),dtype=torch.float64)\n",
    "    # alpha = torch.full(  (batch_size, max_target_length * 2 + 1, )     , float('-inf'))\n",
    "    alpha[:, 0] = log_probs[0, :, blank]\n",
    "    alpha[:, 1] = log_probs[0].gather(1, targets_prime[:, 1].unsqueeze(-1)).squeeze(-1)\n",
    "    mask_third = targets_prime[:, :-2] != targets_prime[:, 2:]\n",
    "\n",
    "    inf_tensor = torch.full_like(alpha[:, :-2], float('-inf'))\n",
    "    for t in range(1, max_input_length):\n",
    "        alpha_next = alpha.clone()\n",
    "        alpha_next[:, 1:] = torch.log(torch.exp(alpha_next[:, 1:]) + torch.exp(alpha[:, :-1]))\n",
    "        alpha_next[:, 2:] = torch.log( torch.exp(alpha_next[:, 2:]) + \n",
    "            torch.exp(torch.where(mask_third, alpha[:, :-2], inf_tensor)) \n",
    "        )\n",
    "        # alpha = torch.log(torch.exp(log_probs[t].gather(1, targets_prime)) * torch.exp(alpha_next))\n",
    "        alpha = log_probs[t].gather(1, targets_prime) + alpha_next\n",
    "        # print(alpha_next.exp())\n",
    "        # print(alpha.exp())\n",
    "        # print('='*20)\n",
    "     \n",
    "    tg = target_lengths.unsqueeze(1)\n",
    "\n",
    "    out = -(alpha.gather(1, tg*2-1).exp() + alpha.gather(1, tg*2).exp() ).log().squeeze()\n",
    "    # out = -alpha[:, -2:].sum(-1).log()\n",
    "    out = (out / target_lengths).mean()\n",
    "    #ctx.save_for_backward(log_probs, targets, input_lengths, target_lengths, alpha)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def batched_ctc_logspace_scale(log_probs: Tensor, targets: Tensor, input_lengths: Tensor, target_lengths: Tensor, blank=0):\n",
    "    # out = torch.nn.functional.ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "    batch_size = targets.size(0)\n",
    "    max_target_length = targets.size(1)\n",
    "    max_input_length  = log_probs.size(0)\n",
    "    targets_prime = targets.new_full((batch_size, 2 * max_target_length + 1,), blank)\n",
    "    targets_prime[:, 1::2] = targets[:, :max_target_length]\n",
    "    # log_probs = log_probs.double()\n",
    "    # probs = log_probs.exp()\n",
    "    # Initialization\n",
    "    # alpha = log_probs.new_zeros((batch_size, max_target_length * 2 + 1, ))\n",
    "    alpha = torch.full(  (batch_size, max_target_length * 2 + 1, )     , float('-inf'),dtype=torch.float64)\n",
    "    # alpha = torch.full(  (batch_size, max_target_length * 2 + 1, )     , float('-inf'))\n",
    "    alpha[:, 0] = log_probs[0, :, blank]\n",
    "    alpha[:, 1] = log_probs[0].gather(1, targets_prime[:, 1].unsqueeze(-1)).squeeze(-1)\n",
    "    mask_third = targets_prime[:, :-2] != targets_prime[:, 2:]\n",
    "    # alpha_next = torch.zeros_like(alpha)\n",
    "    \n",
    "    alpha_next = torch.zeros_like(alpha)\n",
    "    inf_tensor = torch.full_like(alpha[:, :-2], float('-inf'))\n",
    "    for t in range(1, max_input_length):\n",
    "\n",
    "        amax = alpha.max()\n",
    "        alpha_next[:, 2:] =  ( torch.exp(alpha[:, 2:]-amax) + \n",
    "            torch.exp(torch.where(mask_third, alpha[:, :-2], inf_tensor)- amax) +\n",
    "            torch.exp(alpha[:, 1:-1]-amax) )\n",
    "        \n",
    "\n",
    "        alpha_next[:, 1] = torch.exp(alpha[:, 1]-amax) + torch.exp(alpha[:, 0]-amax)\n",
    "        alpha_next[:, 0] = torch.exp(alpha[:, 0]-amax)\n",
    "\n",
    "        # alpha = torch.log(torch.exp(log_probs[t].gather(1, targets_prime)) * torch.exp(alpha_next))\n",
    "        alpha = log_probs[t].gather(1, targets_prime) + torch.log(alpha_next) + amax\n",
    "        # print(alpha_next.exp())\n",
    "        # print(alpha.exp())\n",
    "        # print('='*20)\n",
    "     \n",
    "    tg = target_lengths.unsqueeze(1)\n",
    "\n",
    "    out = -(alpha.gather(1, tg*2-1).exp() + alpha.gather(1, tg*2).exp() ).log().squeeze()\n",
    "    # out = -alpha[:, -2:].sum(-1).log()\n",
    "    out = (out / target_lengths).mean()\n",
    "    #ctx.save_for_backward(log_probs, targets, input_lengths, target_lengths, alpha)\n",
    "    \n",
    "    return out\n",
    "\n",
    "# torch example of using ctc loss\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "# Target are to be padded\n",
    "T = 160      # Input sequence length\n",
    "C = 20      # Number of classes (including blank)\n",
    "N = 40    # Batch size\n",
    "S = 30      # Target sequence length of longest target in batch (padding length)\n",
    "S_min = 10  # Minimum target length, for demonstration purposes\n",
    "# Initialize random batch of input vectors, for *size = (T,N,C)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "# Initialize random batch of targets (0 = blank, 1:C = classes)\n",
    "target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
    "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
    "ctc_loss = nn.CTCLoss()\n",
    "lib_loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "# print(loss)\n",
    "print('libra imp:                    ', lib_loss)\n",
    "print('base imp:                     ', ctc_loss_imp(input, target, input_lengths, target_lengths))\n",
    "print('batched_ctc:                  ',batched_ctc(input, target, input_lengths, target_lengths))\n",
    "print('batched_ctc_v2:               ', batched_ctc_v2(input, target, input_lengths, target_lengths))\n",
    "print('batched_ctc_logspace:         ',batched_ctc_logspace(input, target, input_lengths, target_lengths))\n",
    "print('batched_ctc_logspace_scale:   ',batched_ctc_logspace_scale(input, target, input_lengths, target_lengths))\n",
    "\n",
    "loss = batched_ctc_logspace(input, target, input_lengths, target_lengths)\n",
    "#loss = batched_ctc_logspace_scale(input, target, input_lengths, target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4768e-06, dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_loss -  batched_ctc_logspace_scale(input, target, input_lengths, target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "input.grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr-grad-reconstruction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
